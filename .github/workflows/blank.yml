# This is a basic workflow to help you get started with Actions

name: CI

# Controls when the workflow will run
on:
  # Triggers the workflow on push or pull request events but only for the "master" branch
  push:
    branches: [ "master" ]
  pull_request:
    branches: [ "master" ]

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  build:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: '3.8'
  
  
      # Se configuran las credenciales de AWS    
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{secrets.AWS_ACCESS_KEY_ID}}
          aws-secret-access-key: ${{secrets.AWS_SECRET_ACCESS_KEY}}
          aws-session-token: ${{secrets.AWS_SESSION_TOKEN}}
          aws-region: us-east-1  


      # Se instala el ambiente virtual y se ejecuta el pytest
      - name: Install virtualenv and execute pytest
        run: |
          pip install virtualenv
          virtualenv env
          source env/bin/activate
          pip install -r requirements.txt
          pytest
        
  # Se ejecuta la revision de codigo con flake8
      - name: Revision Flake8
        run: |
          pip install flake8
          flake8 scraper.py

  # Runs a set of commands using the runners shell
      - name: Run a multi-line script
        run: |
          echo Add other actions to build,
          echo test, and deploy your project.
          
  # Se suben las funciones al bucket
      - name: Upload to Bucket
        run: |
          aws s3 cp scraper.py s3://funciones-parcial-big-data/
          aws s3 cp test_scraper.py s3://funciones-parcial-big-data/
          
